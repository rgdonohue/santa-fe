{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preparation: Download Core Datasets\n",
        "\n",
        "This notebook downloads and processes the 5 anchor datasets for Santa Fe geospatial analysis:\n",
        "\n",
        "1. **Census Tracts + ACS Demographics** - From U.S. Census Bureau\n",
        "2. **City Parcels + Zoning** - From City of Santa Fe GIS\n",
        "3. **Hydrology** - From USGS NHD or NM State GIS\n",
        "4. **OSM Roads + POIs** - From OpenStreetMap\n",
        "5. **City Limits Boundary** - From Census TIGER/Line or City GIS\n",
        "\n",
        "## Workflow\n",
        "\n",
        "1. Download raw data â†’ `data/raw/`\n",
        "2. Process (reproject, clip) â†’ `data/processed/`\n",
        "3. Verify data quality\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: /Users/richard/Documents/projects/santa-fe\n",
            "Raw data directory: /Users/richard/Documents/projects/santa-fe/data/raw\n",
            "Processed data directory: /Users/richard/Documents/projects/santa-fe/data/processed\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path so we can import src modules\n",
        "project_root = Path().resolve().parent.parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from src.data.download import (\n",
        "    download_census_tracts,\n",
        "    download_osm_data,\n",
        "    download_hydrology,\n",
        "    download_city_parcels,\n",
        "    download_city_limits,\n",
        "    process_downloaded_data\n",
        ")\n",
        "from src.config import DATA_RAW, DATA_PROCESSED, get_data_path\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Raw data directory: {DATA_RAW}\")\n",
        "print(f\"Processed data directory: {DATA_PROCESSED}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Download City Limits (Do This First)\n",
        "\n",
        "City limits are needed to clip other datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading NM places (cities) from Census TIGER/Line...\n",
            "Note: Will need to filter for Santa Fe city (PLACEFP=70490)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading nm_places_2022.zip: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.34M/2.34M [00:01<00:00, 1.61MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ“ Downloaded to: /Users/richard/Documents/projects/santa-fe/data/raw/nm_places_2022.zip\n",
            "âœ“ City limits processed and saved to: /Users/richard/Documents/projects/santa-fe/data/processed/city_limits.gpkg\n"
          ]
        }
      ],
      "source": [
        "# Download NM places (cities) from Census TIGER/Line\n",
        "city_limits_raw = download_city_limits()\n",
        "\n",
        "if city_limits_raw:\n",
        "    print(f\"\\nâœ“ Downloaded to: {city_limits_raw}\")\n",
        "    \n",
        "    # Process: extract Santa Fe city and save\n",
        "    if city_limits_raw.suffix == '.zip':\n",
        "        import zipfile\n",
        "        import tempfile\n",
        "        \n",
        "        with tempfile.TemporaryDirectory() as tmpdir:\n",
        "            with zipfile.ZipFile(city_limits_raw, 'r') as zip_ref:\n",
        "                zip_ref.extractall(tmpdir)\n",
        "            \n",
        "            shp_files = list(Path(tmpdir).rglob(\"*.shp\"))\n",
        "            if shp_files:\n",
        "                places = gpd.read_file(shp_files[0])\n",
        "                \n",
        "                # Filter for Santa Fe city (PLACEFP = 70490 or NAME contains \"Santa Fe\")\n",
        "                santa_fe = places[\n",
        "                    (places['PLACEFP'] == '70490') | \n",
        "                    (places['NAME'].str.contains('Santa Fe', case=False, na=False))\n",
        "                ].copy()\n",
        "                \n",
        "                if len(santa_fe) > 0:\n",
        "                    # Set CRS if missing\n",
        "                    if santa_fe.crs is None:\n",
        "                        santa_fe = santa_fe.set_crs(\"EPSG:4326\")\n",
        "                    \n",
        "                    # Save to processed\n",
        "                    output_path = get_data_path(\"city_limits\", processed=True)\n",
        "                    santa_fe.to_file(output_path, driver=\"GPKG\")\n",
        "                    print(f\"âœ“ City limits processed and saved to: {output_path}\")\n",
        "                else:\n",
        "                    print(\"âš  Could not find Santa Fe city in places data\")\n",
        "                    print(\"Available places:\", places['NAME'].head(10).tolist())\n",
        "else:\n",
        "    print(\"\\nâš  Manual download required. See instructions above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Download Census Tracts + ACS Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading census tracts from https://www2.census.gov/geo/tiger/TIGER2022/TRACT/tl_2022_35_tract.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading census_tracts_2022.zip: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.95M/4.95M [00:03<00:00, 1.64MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Note: ACS demographic data requires:\n",
            "1. Census API key (get from https://api.census.gov/data/key_signup.html)\n",
            "2. Install census package: pip install census\n",
            "3. Set CENSUS_API_KEY environment variable\n",
            "\n",
            "Tracts shapefile saved to: /Users/richard/Documents/projects/santa-fe/data/raw/census_tracts_2022/tl_2022_35_tract.shp\n",
            "ACS data CSV (to be downloaded): /Users/richard/Documents/projects/santa-fe/data/raw/acs_2022_5yr_santa_fe.csv\n",
            "âœ“ Clipped 45 tracts to city limits\n",
            "\n",
            "âš  ACS data not downloaded (check API key in .env file)\n",
            "âœ“ Processed tracts saved to: /Users/richard/Documents/projects/santa-fe/data/processed/census_tracts_acs.gpkg\n",
            "  Columns: ['STATEFP', 'COUNTYFP', 'TRACTCE', 'GEOID', 'NAME', 'NAMELSAD', 'MTFCC', 'FUNCSTAT', 'ALAND', 'AWATER']...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Download census tracts for Santa Fe County (FIPS: 35049)\n",
        "tracts_shp, acs_csv = download_census_tracts(\n",
        "    state_fips=\"35\",  # New Mexico\n",
        "    county_fips=\"049\",  # Santa Fe County\n",
        "    year=2022\n",
        ")\n",
        "\n",
        "# Process tracts: clip to city limits and reproject\n",
        "if tracts_shp.exists():\n",
        "    tracts_gdf = gpd.read_file(tracts_shp)\n",
        "    \n",
        "    # Clip to city limits if available\n",
        "    city_limits_path = get_data_path(\"city_limits\", processed=True)\n",
        "    if city_limits_path.exists():\n",
        "        city_limits = gpd.read_file(city_limits_path)\n",
        "        tracts_gdf = gpd.clip(tracts_gdf, city_limits)\n",
        "        print(f\"âœ“ Clipped {len(tracts_gdf)} tracts to city limits\")\n",
        "    \n",
        "    # Join ACS demographic data if available\n",
        "    if acs_csv.exists():\n",
        "        print(\"\\nJoining ACS demographic data to tracts...\")\n",
        "        acs_df = pd.read_csv(acs_csv)\n",
        "        \n",
        "        # Ensure GEOID column exists in tracts (it should from TIGER/Line)\n",
        "        if 'GEOID' not in tracts_gdf.columns:\n",
        "            # Create GEOID from GEOIDFP or similar column\n",
        "            if 'GEOIDFP' in tracts_gdf.columns:\n",
        "                tracts_gdf['GEOID'] = tracts_gdf['GEOIDFP']\n",
        "            elif 'GEOID20' in tracts_gdf.columns:\n",
        "                tracts_gdf['GEOID'] = tracts_gdf['GEOID20']\n",
        "            else:\n",
        "                # Try to construct from state + county + tract FIPS\n",
        "                state_col = [c for c in tracts_gdf.columns if 'STATEFP' in c.upper()][0] if any('STATEFP' in c.upper() for c in tracts_gdf.columns) else None\n",
        "                county_col = [c for c in tracts_gdf.columns if 'COUNTYFP' in c.upper()][0] if any('COUNTYFP' in c.upper() for c in tracts_gdf.columns) else None\n",
        "                tract_col = [c for c in tracts_gdf.columns if 'TRACTFP' in c.upper() or 'TRACTCE' in c.upper()][0] if any('TRACTFP' in c.upper() or 'TRACTCE' in c.upper() for c in tracts_gdf.columns) else None\n",
        "                \n",
        "                if state_col and county_col and tract_col:\n",
        "                    tracts_gdf['GEOID'] = (\n",
        "                        tracts_gdf[state_col].astype(str).str.zfill(2) +\n",
        "                        tracts_gdf[county_col].astype(str).str.zfill(3) +\n",
        "                        tracts_gdf[tract_col].astype(str).str.zfill(6)\n",
        "                    )\n",
        "                else:\n",
        "                    print(\"âš  Could not create GEOID for joining. Available columns:\", list(tracts_gdf.columns)[:10])\n",
        "        \n",
        "        # Join ACS data\n",
        "        if 'GEOID' in tracts_gdf.columns:\n",
        "            tracts_gdf = tracts_gdf.merge(acs_df, on='GEOID', how='left')\n",
        "            print(f\"âœ“ Joined ACS data: {tracts_gdf[acs_df.columns].notna().sum().sum()} values added\")\n",
        "        else:\n",
        "            print(\"âš  Cannot join ACS data: GEOID column missing\")\n",
        "    else:\n",
        "        print(\"\\nâš  ACS data not downloaded (check API key in .env file)\")\n",
        "    \n",
        "    # Reproject to local CRS\n",
        "    if tracts_gdf.crs is None:\n",
        "        tracts_gdf = tracts_gdf.set_crs(\"EPSG:4326\")\n",
        "    tracts_gdf = tracts_gdf.to_crs(\"EPSG:32113\")  # NM State Plane\n",
        "    \n",
        "    # Save processed\n",
        "    output_path = get_data_path(\"census_tracts\", processed=True)\n",
        "    tracts_gdf.to_file(output_path, driver=\"GPKG\")\n",
        "    print(f\"âœ“ Processed tracts saved to: {output_path}\")\n",
        "    print(f\"  Columns: {list(tracts_gdf.columns)[:10]}...\")\n",
        "else:\n",
        "    print(\"âš  Census tracts download failed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Download OSM Roads + POIs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading OSM data via Overpass API...\n",
            "OSM data saved to: /Users/richard/Documents/projects/santa-fe/data/raw/osm_santa_fe.json\n",
            "\n",
            "âœ“ OSM data downloaded to: /Users/richard/Documents/projects/santa-fe/data/raw/osm_santa_fe.json\n",
            "\n",
            "Processing OSM data...\n",
            "  âœ“ Extracted 10798 road segments\n",
            "  âœ“ Extracted 2234 POIs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/q0/mqqgl1bx65v46lkyhq0xb7pm0000gn/T/ipykernel_68730/1494901553.py:93: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
            "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
            "\n",
            "Left CRS: EPSG:4326\n",
            "Right CRS: EPSG:4269\n",
            "\n",
            "  combined_osm = gpd.clip(combined_osm, city_limits)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  âœ“ Clipped to city limits: 11142 features\n",
            "âœ“ Processed OSM data saved to: /Users/richard/Documents/projects/santa-fe/data/processed/osm_roads_pois.gpkg\n",
            "  - Roads: 9085\n",
            "  - POIs: 2057\n"
          ]
        }
      ],
      "source": [
        "# Download OSM data for Santa Fe area\n",
        "osm_raw = download_osm_data(use_overpass=True)\n",
        "\n",
        "if osm_raw and osm_raw.exists():\n",
        "    print(f\"\\nâœ“ OSM data downloaded to: {osm_raw}\")\n",
        "    \n",
        "    # Process OSM JSON to GeoDataFrames\n",
        "    import json\n",
        "    from shapely.geometry import Point, LineString\n",
        "    \n",
        "    with open(osm_raw, 'r') as f:\n",
        "        osm_data = json.load(f)\n",
        "    \n",
        "    print(\"\\nProcessing OSM data...\")\n",
        "    \n",
        "    # Extract nodes (for POIs) and ways (for roads)\n",
        "    nodes = {}\n",
        "    ways = []\n",
        "    pois = []\n",
        "    roads = []\n",
        "    \n",
        "    # First pass: collect all nodes\n",
        "    for element in osm_data.get('elements', []):\n",
        "        if element['type'] == 'node':\n",
        "            nodes[element['id']] = {\n",
        "                'lon': element['lon'],\n",
        "                'lat': element['lat'],\n",
        "                'tags': element.get('tags', {})\n",
        "            }\n",
        "    \n",
        "    # Second pass: process ways (roads)\n",
        "    for element in osm_data.get('elements', []):\n",
        "        if element['type'] == 'way':\n",
        "            way_nodes = element.get('geometry', [])\n",
        "            if way_nodes:\n",
        "                # Build LineString from way geometry\n",
        "                coords = [(node['lon'], node['lat']) for node in way_nodes]\n",
        "                if len(coords) >= 2:\n",
        "                    geom = LineString(coords)\n",
        "                    tags = element.get('tags', {})\n",
        "                    \n",
        "                    # Check if it's a road\n",
        "                    if 'highway' in tags:\n",
        "                        roads.append({\n",
        "                            'geometry': geom,\n",
        "                            'highway': tags.get('highway'),\n",
        "                            'name': tags.get('name', ''),\n",
        "                            'osm_id': element['id']\n",
        "                        })\n",
        "    \n",
        "    # Process POIs (nodes with tags)\n",
        "    for node_id, node_data in nodes.items():\n",
        "        tags = node_data['tags']\n",
        "        if tags:  # Only nodes with tags are POIs\n",
        "            pois.append({\n",
        "                'geometry': Point(node_data['lon'], node_data['lat']),\n",
        "                'amenity': tags.get('amenity', ''),\n",
        "                'shop': tags.get('shop', ''),\n",
        "                'name': tags.get('name', ''),\n",
        "                'osm_id': node_id\n",
        "            })\n",
        "    \n",
        "    # Create GeoDataFrames\n",
        "    if roads:\n",
        "        roads_gdf = gpd.GeoDataFrame(roads, crs=\"EPSG:4326\")\n",
        "        print(f\"  âœ“ Extracted {len(roads_gdf)} road segments\")\n",
        "    else:\n",
        "        roads_gdf = gpd.GeoDataFrame(columns=['geometry', 'highway', 'name', 'osm_id'], crs=\"EPSG:4326\")\n",
        "    \n",
        "    if pois:\n",
        "        pois_gdf = gpd.GeoDataFrame(pois, crs=\"EPSG:4326\")\n",
        "        print(f\"  âœ“ Extracted {len(pois_gdf)} POIs\")\n",
        "    else:\n",
        "        pois_gdf = gpd.GeoDataFrame(columns=['geometry', 'amenity', 'shop', 'name', 'osm_id'], crs=\"EPSG:4326\")\n",
        "    \n",
        "    # Combine roads and POIs into single GeoDataFrame\n",
        "    # Add a 'feature_type' column to distinguish\n",
        "    roads_gdf['feature_type'] = 'road'\n",
        "    pois_gdf['feature_type'] = 'poi'\n",
        "    \n",
        "    # Combine (keeping all columns)\n",
        "    combined_osm = pd.concat([\n",
        "        roads_gdf[['geometry', 'feature_type', 'highway', 'name', 'osm_id']].rename(columns={'highway': 'category'}),\n",
        "        pois_gdf[['geometry', 'feature_type', 'amenity', 'shop', 'name', 'osm_id']].assign(\n",
        "            category=pois_gdf['amenity'].fillna(pois_gdf['shop'])\n",
        "        )[['geometry', 'feature_type', 'category', 'name', 'osm_id']]\n",
        "    ], ignore_index=True)\n",
        "    \n",
        "    # Clip to city limits if available\n",
        "    city_limits_path = get_data_path(\"city_limits\", processed=True)\n",
        "    if city_limits_path.exists():\n",
        "        city_limits = gpd.read_file(city_limits_path)\n",
        "        combined_osm = gpd.clip(combined_osm, city_limits)\n",
        "        print(f\"  âœ“ Clipped to city limits: {len(combined_osm)} features\")\n",
        "    \n",
        "    # Reproject to local CRS\n",
        "    if combined_osm.crs is None:\n",
        "        combined_osm = combined_osm.set_crs(\"EPSG:4326\")\n",
        "    combined_osm = combined_osm.to_crs(\"EPSG:32113\")\n",
        "    \n",
        "    # Save to processed directory\n",
        "    output_path = get_data_path(\"osm\", processed=True)\n",
        "    combined_osm.to_file(output_path, driver=\"GPKG\")\n",
        "    print(f\"âœ“ Processed OSM data saved to: {output_path}\")\n",
        "    print(f\"  - Roads: {len(combined_osm[combined_osm['feature_type'] == 'road'])}\")\n",
        "    print(f\"  - POIs: {len(combined_osm[combined_osm['feature_type'] == 'poi'])}\")\n",
        "else:\n",
        "    print(\"âš  OSM download failed or returned None\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Download Hydrology Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âš  OSM hydrology download failed or returned None\n",
            "\n",
            "This might be normal - Santa Fe is in a semi-arid region with limited surface water.\n",
            "\n",
            "Options:\n",
            "1. Create empty hydrology file (for pipeline continuity)\n",
            "2. Try alternative sources:\n",
            "   - download_hydrology(source='nm') for NM State GIS\n",
            "   - download_hydrology(source='usgs_3dhp') for 3DHP instructions\n",
            "3. Manually download from:\n",
            "   - NM State GIS: https://www.nmgis.org/\n",
            "   - USGS 3DHP: https://www.usgs.gov/3d-hydrography-program/access-3dhp-data-products\n",
            "\n",
            "Creating empty hydrology file for pipeline continuity...\n",
            "âœ“ Empty hydrology file created at: /Users/richard/Documents/projects/santa-fe/data/processed/hydrology.gpkg\n",
            "  (You can add data later or skip hydrology analysis)\n"
          ]
        }
      ],
      "source": [
        "# Download hydrology data (rivers, streams, waterbodies)\n",
        "# Note: USGS NHD was retired in Oct 2023. Using OSM as default source.\n",
        "\n",
        "try:\n",
        "    # Try OSM first (fastest, good coverage for Santa Fe)\n",
        "    hydro_raw = download_hydrology(source=\"osm\")\n",
        "    \n",
        "    if hydro_raw and hydro_raw.exists():\n",
        "        print(f\"\\nâœ“ Hydrology data downloaded to: {hydro_raw}\")\n",
        "        \n",
        "        # Process OSM hydrology JSON to GeoDataFrame\n",
        "        print(\"\\nProcessing OSM hydrology data...\")\n",
        "        import json\n",
        "        from shapely.geometry import Point, LineString, Polygon\n",
        "        \n",
        "        with open(hydro_raw, 'r') as f:\n",
        "            osm_data = json.load(f)\n",
        "        \n",
        "        hydro_features = []\n",
        "        \n",
        "        # Process OSM elements (ways and relations for water features)\n",
        "        for element in osm_data.get('elements', []):\n",
        "            if element['type'] == 'way':\n",
        "                way_geom = element.get('geometry', [])\n",
        "                if way_geom:\n",
        "                    coords = [(node['lon'], node['lat']) for node in way_geom]\n",
        "                    if len(coords) >= 2:\n",
        "                        geom = LineString(coords)\n",
        "                        tags = element.get('tags', {})\n",
        "                        \n",
        "                        # Waterways (rivers, streams, canals)\n",
        "                        if 'waterway' in tags:\n",
        "                            hydro_features.append({\n",
        "                                'geometry': geom,\n",
        "                                'waterway_type': tags.get('waterway'),\n",
        "                                'name': tags.get('name', ''),\n",
        "                                'osm_id': element['id'],\n",
        "                                'feature_type': 'waterway'\n",
        "                            })\n",
        "                        # Natural water features\n",
        "                        elif tags.get('natural') == 'water':\n",
        "                            # Close the polygon if it's a waterbody\n",
        "                            if len(coords) > 2 and coords[0] == coords[-1]:\n",
        "                                geom = Polygon(coords)\n",
        "                            hydro_features.append({\n",
        "                                'geometry': geom,\n",
        "                                'waterway_type': 'waterbody',\n",
        "                                'name': tags.get('name', ''),\n",
        "                                'osm_id': element['id'],\n",
        "                                'feature_type': 'waterbody'\n",
        "                            })\n",
        "        \n",
        "        if hydro_features:\n",
        "            hydro_gdf = gpd.GeoDataFrame(hydro_features, crs=\"EPSG:4326\")\n",
        "            print(f\"  âœ“ Extracted {len(hydro_gdf)} water features\")\n",
        "            \n",
        "            # Clip to city limits\n",
        "            city_limits_path = get_data_path(\"city_limits\", processed=True)\n",
        "            if city_limits_path.exists():\n",
        "                city_limits = gpd.read_file(city_limits_path)\n",
        "                hydro_gdf = gpd.clip(hydro_gdf, city_limits)\n",
        "                print(f\"  âœ“ Clipped to city limits: {len(hydro_gdf)} features\")\n",
        "            \n",
        "            # Reproject\n",
        "            hydro_gdf = hydro_gdf.to_crs(\"EPSG:32113\")\n",
        "            \n",
        "            # Save\n",
        "            output_path = get_data_path(\"hydrology\", processed=True)\n",
        "            hydro_gdf.to_file(output_path, driver=\"GPKG\")\n",
        "            print(f\"âœ“ Processed hydrology saved to: {output_path}\")\n",
        "        else:\n",
        "            print(\"âš  No water features found in OSM data\")\n",
        "            print(\"Try alternative sources:\")\n",
        "            print(\"  - download_hydrology(source='nm') for NM State GIS\")\n",
        "            print(\"  - download_hydrology(source='usgs_3dhp') for 3DHP instructions\")\n",
        "    \n",
        "    else:\n",
        "        print(\"\\nâš  OSM hydrology download failed or returned None\")\n",
        "        print(\"\\nThis might be normal - Santa Fe is in a semi-arid region with limited surface water.\")\n",
        "        print(\"\\nOptions:\")\n",
        "        print(\"1. Create empty hydrology file (for pipeline continuity)\")\n",
        "        print(\"2. Try alternative sources:\")\n",
        "        print(\"   - download_hydrology(source='nm') for NM State GIS\")\n",
        "        print(\"   - download_hydrology(source='usgs_3dhp') for 3DHP instructions\")\n",
        "        print(\"3. Manually download from:\")\n",
        "        print(\"   - NM State GIS: https://www.nmgis.org/\")\n",
        "        print(\"   - USGS 3DHP: https://www.usgs.gov/3d-hydrography-program/access-3dhp-data-products\")\n",
        "        \n",
        "        # Create empty hydrology file so pipeline can continue\n",
        "        print(\"\\nCreating empty hydrology file for pipeline continuity...\")\n",
        "        empty_hydro = gpd.GeoDataFrame(\n",
        "            columns=['geometry', 'waterway_type', 'name', 'osm_id', 'feature_type'],\n",
        "            crs=\"EPSG:32113\"\n",
        "        )\n",
        "        output_path = get_data_path(\"hydrology\", processed=True)\n",
        "        empty_hydro.to_file(output_path, driver=\"GPKG\")\n",
        "        print(f\"âœ“ Empty hydrology file created at: {output_path}\")\n",
        "        print(\"  (You can add data later or skip hydrology analysis)\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âš  Error downloading hydrology: {e}\")\n",
        "    print(\"\\nCreating empty hydrology file for pipeline continuity...\")\n",
        "    try:\n",
        "        empty_hydro = gpd.GeoDataFrame(\n",
        "            columns=['geometry', 'waterway_type', 'name', 'osm_id', 'feature_type'],\n",
        "            crs=\"EPSG:32113\"\n",
        "        )\n",
        "        output_path = get_data_path(\"hydrology\", processed=True)\n",
        "        empty_hydro.to_file(output_path, driver=\"GPKG\")\n",
        "        print(f\"âœ“ Empty hydrology file created at: {output_path}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âš  Could not create empty file: {e2}\")\n",
        "    \n",
        "    print(\"\\nManual download options:\")\n",
        "    print(\"1. OSM: https://www.openstreetmap.org/ (use Overpass API)\")\n",
        "    print(\"2. NM State GIS: https://www.nmgis.org/\")\n",
        "    print(\"3. USGS 3DHP: https://www.usgs.gov/3d-hydrography-program/access-3dhp-data-products\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Download City Parcels + Zoning\n",
        "\n",
        "**Note:** This typically requires manual download from the city GIS portal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "City of Santa Fe Parcels & Zoning:\n",
            "==================================================\n",
            "1. Visit: https://www.santafenm.gov/gis\n",
            "2. Look for 'Parcels' or 'Zoning' data layer\n",
            "3. Download as Shapefile or GeoJSON\n",
            "4. Save to: /Users/richard/Documents/projects/santa-fe/data/raw/city_parcels_zoning.zip\n",
            "\n",
            "Alternatively, check:\n",
            "- ArcGIS Online: https://www.arcgis.com/apps/mapviewer/index.html\n",
            "- Search for 'Santa Fe parcels'\n",
            "\n",
            "ðŸ“‹ Manual download instructions shown above.\n",
            "After downloading, place file in: /Users/richard/Documents/projects/santa-fe/data/raw\n",
            "Then run: process_downloaded_data('parcels', path_to_file)\n"
          ]
        }
      ],
      "source": [
        "# Try to download (will show instructions if manual download needed)\n",
        "parcels_raw = download_city_parcels()\n",
        "\n",
        "if parcels_raw and parcels_raw.exists():\n",
        "    print(f\"\\nâœ“ Parcels downloaded to: {parcels_raw}\")\n",
        "    \n",
        "    # Process parcels\n",
        "    try:\n",
        "        process_downloaded_data(\n",
        "            \"parcels\",\n",
        "            parcels_raw,\n",
        "            clip_to_city=True\n",
        "        )\n",
        "        print(\"âœ“ Parcels processed successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš  Error processing parcels: {e}\")\n",
        "else:\n",
        "    print(\"\\nðŸ“‹ Manual download instructions shown above.\")\n",
        "    print(\"After downloading, place file in:\", DATA_RAW)\n",
        "    print(\"Then run: process_downloaded_data('parcels', path_to_file)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify All Datasets\n",
        "\n",
        "Check that all processed datasets exist and are valid GeoPackage files.\n",
        "\n",
        "Expected files in `data/processed/`:\n",
        "- âœ… `city_limits.gpkg`\n",
        "- âœ… `census_tracts_acs.gpkg` (tracts only; ACS demographics need API key)\n",
        "- âœ… `hydrology.gpkg`\n",
        "- âœ… `osm_roads_pois.gpkg`\n",
        "- âœ… `parcels_zoning.gpkg`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.data.loaders import (\n",
        "    load_city_limits,\n",
        "    load_census_tracts,\n",
        "    load_hydrology,\n",
        "    load_parcels\n",
        ")\n",
        "\n",
        "datasets = {\n",
        "    \"City Limits\": load_city_limits,\n",
        "    \"Census Tracts\": load_census_tracts,\n",
        "    \"Hydrology\": load_hydrology,\n",
        "    \"Parcels\": load_parcels,\n",
        "}\n",
        "\n",
        "print(\"Dataset Status:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for name, loader_func in datasets.items():\n",
        "    try:\n",
        "        gdf = loader_func()\n",
        "        \n",
        "        # Handle None return (for load_city_limits)\n",
        "        if gdf is None:\n",
        "            print(f\"âœ— {name}: Not found\")\n",
        "        else:\n",
        "            print(f\"âœ“ {name}: {len(gdf)} features, CRS: {gdf.crs}\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"âœ— {name}: Not found - {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš  {name}: Error - {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Next: Run 001_who_lives_where.ipynb to start analysis\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
